---
title: "MUSA508_Final_Project"
output:
  html_document:
    code_folding: hide
---

# Introduction
The analysis presented here is for the development of the machine learning model behind the app **Eat Safe**. Eat Safe is a public health safety app that predicts whether a restaurant will fail its next sanitation inspection by the Department of Public Health in Chicago. Environmental factors and past inspection scores are accounted for in the model, which will be updated annually to reflect updated information. 

In 2018, Yelp piloted incorporating previous health inspection scores for restaurants into their app, but this has stirred discontent among restaurant owners. For one, the health inspection score could be outdated (as the last health inspection could have occurred almost 2 years ago). The restaurant could have made corrections to the violation ever since, and an outdated health inspection score can be very harmful to a restaurant's business. Additionally, some restaurant owners felt that a past health inspection score placed an unfair burden on restaurants, as some health code violations such as rodent infestations could be more related to sanitation issues that have been plaguing the neighborhood. 

Eat Safe aims to reduce the spread of foodborne illnesses, while providing objective assessments that protect restaurants' reputations. Instead of showing the past inspection score which could have been from 2 years ago, we provide a forecast of whether a restaurant is likely to pass or fail its next inspection, using the latest updated information.  

The predicted inspection score can be incorporated into restaurant reviews on sites such as Yelp, Google Maps, and food blogs to enhance awareness of the food safety of restaurants.  

For more information on EatSafe, check out this promo video: [INSERT SABRINA VID]

The model developed here utilizes logistic regression, determining the likelihood of failing inspection and allowing us to classify a restaurant as likely to "fail" their next inspection or "pass" their next inspection. This allows for clear messaging in the app and through the API that a restaurant is "sure safe" or that a restaurant is potentially "at risk of failing inspection". 

Data used in this analysis came from the [Chicago Data Portal](https://data.cityofchicago.org/). The inspection data contains inspections of restaurants and other food establishments in Chicago since 2010, with this analysis focusing specifically on restaurants. Inspections are performed by staff from the Chicago Department of Public Healthâ€™s Food Protection Program using a standardized procedure. Other open data we utilize include Chicago neighborhoods, 311 requests, and liquor licenses. Other data included in this analysis includes census data from the American Community Survey. We also use weather data using the riem package, which allows us to pull weather data from stations across the world. Common violations for restaurants are due to improper temperature control for food, so the model also incorporates temperature.

The model developed here uses spatial features such as neighborhoods and distance to 311 requests to identify the risk of failing an inspection.  Further features about the restaurant and its past inspections are developed. 

# Setup

```{r setup_13, cache=TRUE, message=FALSE}
library(tidyverse)
library(sf)
library(lubridate)
library(tigris)
library(tidycensus)
library(viridis)
library(riem)
library(gridExtra)
library(knitr)
library(kableExtra)
library(RSocrata)
library(FNN)
library(caret)
library(plotROC)

plotTheme <- theme(
  plot.title =element_text(size=12),
  plot.subtitle = element_text(size=8),
  plot.caption = element_text(size = 6),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title.y = element_text(size = 10),
  # Set the entire chart region to blank
  panel.background=element_blank(),
  plot.background=element_blank(),
  #panel.border=element_rect(colour="#F0F0F0"),
  # Format the grid
  panel.grid.major=element_line(colour="#D0D0D0",size=.2),
  axis.ticks=element_blank())

mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}

palette5 <- c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c")
palette5b <- c("#f0f9e8","#bae4bc","#7bccc4","#43a2ca","#0868ac")
palette4 <- c("#D2FBD4","#92BCAB","#527D82","#123F5A")
palette2 <- c("#6baed6","#08519c")

```

```{r setup_2, cache=TRUE, message=FALSE}
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
    output <-
      as.data.frame(nn) %>%
      rownames_to_column(var = "thisPoint") %>%
      gather(points, point_distance, V1:ncol(.)) %>%
      arrange(as.numeric(thisPoint)) %>%
      group_by(thisPoint) %>%
      dplyr::summarize(pointDistance = mean(point_distance)) %>%
      arrange(as.numeric(thisPoint)) %>% 
      dplyr::select(-thisPoint) %>%
      pull()
  
  return(output)  
}

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}
q5 <- function(variable) {as.factor(ntile(variable, 5))}
```

```{r load_api_key, message = FALSE}
# Load API key
census_api_key("d8b938a81d19a2811d021f339295fbf6135f7d36", overwrite = TRUE)
```

```{r load_data}
# Read in the data with RSocrata package
inspections <- read.socrata(
  "https://data.cityofchicago.org/resource/4ijn-s7e5.json",
  app_token = "soPSENlY4ttB95Y2PJMQLdLQL",
  email     = "willi2eh@upenn.edu",
  password  = "Triscuit3!"
)

# Convert to sf object
# Filter for only restaurants that are in business
inspections <- st_as_sf(inspections, coords = c("location.latitude", "location.longitude"), 
                 crs = 4326, agr = "constant", na.fail=FALSE) %>%
   st_transform('ESRI:102271') %>%
  filter(results != "Out of Business") %>%
  filter(results != "Not Ready") %>%
  filter(inspection_type != "Non-Inspection") %>%
  filter(facility_type == "Restaurant") 

# I had to just download this locally and read in: https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-City/ewy2-6yfk
ChicagoBoundary <- st_read("BoundariesCity.geojson")%>%
   st_transform('ESRI:102271') 

```

```{r feature_engineering, warning=FALSE}

# results_numeric
# Outcome variable recoded to numeric binary variable: Fail inspection = 1 & Pass inspection = 0
# If no entry, but violation -> fail
# If no entry, but no violations -> pass
# If pass with conditions -> pass
inspections <- inspections %>%
  mutate(results_numeric = ifelse(inspections$results == "Fail", 1, ifelse(((inspections$results == "No Entry")&(!is.na(inspections$violations))), 1, 0)))

# violations_count
# This code counts the number of times the character | is used (this separates the violations) and adds 1 (because there isn't one in front of the first)
library(stringr)
inspections <- inspections %>%
  mutate(violations_count = str_count(inspections$violations, coll("| "))) 
inspections <- inspections %>%
  mutate(violations_count = ifelse(!is.na(inspections$violations_count), inspections$violations_count + 1, 0))

# past_inspect & past_failed_inspect
# Create feature for how many previous inspections they have had & how many of those they have failed
inspections <- inspections %>%
  arrange(dba_name, inspection_date) %>%
  group_by(dba_name) %>%
  mutate(total_inspect = 1:n()) %>%
  # Create a column showing fail_result, fail is 1, pass is 0
  mutate(fail_result = ifelse(results == "Fail", 1, 0)) %>%
  # Calculate the cumulative sum of fail_result
  mutate(failed_inspect = cumsum(fail_result)) %>%
  # Remove fail_result
  select(-fail_result) %>%
  # Sort the data frame by Date
  arrange(inspection_date)

inspections <- inspections %>%
  mutate(past_inspect = ifelse(total_inspect == 0, 0, total_inspect - 1)) %>%
  mutate(past_failed_inspect = ifelse(results == "Fail" & failed_inspect != 0, 
                                      failed_inspect - 1,
                                      failed_inspect)) %>%
  select(-total_inspect, -failed_inspect)

# no_of_days
# Create feature for days since last inspection
inspections <- inspections %>%
  arrange(dba_name, inspection_date) %>%
  group_by(dba_name) %>%
  mutate(no_of_days = round(c(0, diff(inspection_date)), 0))

# days_operating
# Create feature for days the restaurant has been operating (days since first inspection)
inspections <- inspections %>%
  arrange(dba_name, inspection_date) %>%
  group_by(dba_name) %>% 
  mutate(days_operating = today() - min(ymd(inspection_date)))

# high_risk
# Create feature designating high risk vs everything else
inspections <- inspections %>%
  mutate(high_risk = ifelse(risk == "Risk 1 (High)", 1, 0))

# critical_violations
# Create a feature that determines the number of "serious" or "critical" violations per inspection
inspections$critical_violations <- str_count(inspections$violations, "SERIOUS|CRITICAL")

```

```{r neighborhoods, cache = TRUE, message = FALSE, warning = FALSE, results = 'hide'}
# I had to just download this locally and read in: https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Neighborhoods/bbvz-uum9
chicagoNeighborhoods <- st_read("BoundariesNeighborhoods.geojson") %>%
   st_transform('ESRI:102271') 

# add neighborhoods to inspections data - this is an sf object
inspections <- st_join(inspections %>% st_transform(crs=4326),
        chicagoNeighborhoods %>%
          st_transform(crs=4326),
        join=st_intersects,
              left = TRUE) 

inspections <- inspections %>%
        select(-shape_area, -shape_len)

```

```{r use_nn_function}
# Pull in 311 Requests

#sanitation <- read.socrata(
 # "https://data.cityofchicago.org/resource/me59-5fac.json",
  #app_token = "soPSENlY4ttB95Y2PJMQLdLQL",
  #email     = "willi2eh@upenn.edu",
  #password  = "Triscuit3!"
#)
# Convert to sf object & filter for 2016
#sanitation <- st_as_sf(sanitation, coords = c("latitude", "longitude"), 
 #                crs = 4326, agr = "constant", na.fail=FALSE) %>%
#  dplyr::filter((creation_date > as.POSIXct("2016-01-01")) & (creation_date < as.POSIXct("2017-01-01"))) %>%
 # st_transform(st_crs(inspections))

sanitation <-
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Sanitation-Code-Complaints-Hi/me59-5fac") %>%
    mutate(year = substr(creation_date,1,4)) %>% filter(year == "2016") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    mutate(Legend = "Sanitation") %>%
    st_transform(st_crs(inspections))

# rodents
rodents <-
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Rodent-Baiting-Historical/97t6-zrhs") %>%
    mutate(year = substr(creation_date,1,4)) %>% filter(year == "2016") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    mutate(Legend = "Rodents") %>%
    st_transform(st_crs(inspections))

# liquor licenses 
liquor <-
  read.socrata("https://data.cityofchicago.org/Community-Economic-Development/Business-Licenses-Current-Liquor-and-Public-Places/nrmj-3kcf") %>%
    dplyr::select(Y = LATITUDE, X = LONGITUDE) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    mutate(Legend = "Liquor") %>%
    st_transform(st_crs(inspections))

# Create distance variables
st_c <- st_coordinates

# for some reason the column dba_name is causing an error on the nn_function - dropping it since aka_name is similar
inspections <- inspections %>%
  select(-dba_name) 

inspections <- na.omit(inspections)

inspections <-
  inspections %>%
    dplyr::mutate(
      sanitation_nn1 = nn_function(st_c(inspections), st_c(sanitation), 1),
      sanitation_nn2 = nn_function(st_c(inspections), st_c(sanitation), 2),
      sanitation_nn3 = nn_function(st_c(inspections), st_c(sanitation), 3),
      sanitation_nn4 = nn_function(st_c(inspections), st_c(sanitation), 4),
      sanitation_nn5 = nn_function(st_c(inspections), st_c(sanitation), 5))

inspections <-
  inspections %>%
    dplyr::mutate(
      rodents_nn1 = nn_function(st_c(inspections), st_c(rodents), 1),
      rodents_nn2 = nn_function(st_c(inspections), st_c(rodents), 2),
      rodents_nn3 = nn_function(st_c(inspections), st_c(rodents), 3),
      rodents_nn4 = nn_function(st_c(inspections), st_c(rodents), 4),
      rodents_nn5 = nn_function(st_c(inspections), st_c(rodents), 5))

inspections <-
  inspections %>%
    dplyr::mutate(
      liquor_nn1 = nn_function(st_c(inspections), st_c(liquor), 1),
      liquor_nn2 = nn_function(st_c(inspections), st_c(liquor), 2),
      liquor_nn3 = nn_function(st_c(inspections), st_c(liquor), 3),
      liquor_nn4 = nn_function(st_c(inspections), st_c(liquor), 4),
      liquor_nn5 = nn_function(st_c(inspections), st_c(liquor), 5))

```

```{r inspections_2016}
# Subset for inspections in 2016 
# and then another df for 2017
# We will estimate a model using inspection data from 2016 to predict for 2017
# Doing these years because there was a change in violations in 7/2018 that may impact results: http://dev.cityofchicago.org/open%20data/data%20portal/2018/06/29/food-violations-changes.html
inspections16 <- inspections %>%
   dplyr::filter((inspection_date > as.POSIXct("2016-01-01")) & (inspection_date < as.POSIXct("2017-01-01")))

inspections17 <- inspections %>%
   dplyr::filter((inspection_date > as.POSIXct("2017-01-01")) & (inspection_date < as.POSIXct("2018-01-01")))

inspections18 <- inspections %>%
   dplyr::filter((inspection_date > as.POSIXct("2018-01-01")) & (inspection_date < as.POSIXct("2019-01-01")))

```

```{r get_16_census, message=FALSE, warning=FALSE, cache=TRUE, results = 'hide'}
# Get 2016 census data
chicagoCensus <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E","B06011_001"), 
          year = 2016, state="IL", geometry=T, county=c("Cook"), output = "wide") %>%
  rename(TotalPop = B01001_001E,
         NumberWhites = B01001A_001E,
         Median_Income = B06011_001E) %>%
  mutate(percentWhite = ((NumberWhites / TotalPop)*100),
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))

# combine inspection df and census df
inspections16 <- st_join(inspections16 %>% st_transform(crs=4326),
        chicagoCensus %>%
          st_transform(crs=4326),
        join=st_intersects,
              left = TRUE) 

```

```{r get_17_census, message=FALSE, warning=FALSE, cache=TRUE, results = 'hide'}
# Get 2017 census data
chicagoCensus <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E","B06011_001"), 
          year = 2017, state="IL", geometry=T, county=c("Cook"), output = "wide") %>%
  rename(TotalPop = B01001_001E,
         NumberWhites = B01001A_001E,
         Median_Income = B06011_001E) %>%
  mutate(percentWhite = ((NumberWhites / TotalPop)*100),
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))

# combine inspection df and census df
inspections17 <- st_join(inspections17%>% st_transform(crs=4326),
        chicagoCensus %>%
          st_transform(crs=4326),
        join=st_intersects,
              left = TRUE) 

```

```{r get_18_census, message=FALSE, warning=FALSE, cache=TRUE, results = 'hide'}
# Get 2018 census data
chicagoCensus <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E","B06011_001"), 
          year = 2018, state="IL", geometry=T, county=c("Cook"), output = "wide") %>%
  rename(TotalPop = B01001_001E,
         NumberWhites = B01001A_001E,
         Median_Income = B06011_001E) %>%
  mutate(percentWhite = ((NumberWhites / TotalPop)*100),
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))

# combine inspection df and census df
inspections18 <- st_join(inspections18%>% st_transform(crs=4326),
        chicagoCensus %>%
          st_transform(crs=4326),
        join=st_intersects,
              left = TRUE) 

```

```{r import_weather_16, message = FALSE, warning = FALSE, cache = TRUE}
# Get 2016 weather data
weather.Panel <- 
  riem_measures(station = "ORD", date_start = "2016-01-01", date_end = "2016-12-31") %>%
  dplyr::select(valid, tmpf, p01i, sknt)%>%
  replace(is.na(.), 0) %>%
    mutate(inspection_date = as.Date(ymd_h(substr(valid,1,13)))) %>%
    mutate(week = week(inspection_date),
           dotw = wday(inspection_date, label=TRUE)) %>%
    group_by(inspection_date) %>%
    summarize(Temperature = max(tmpf),
              Precipitation = sum(p01i),
              Wind_Speed = max(sknt)) %>%
    mutate(Temperature = ifelse(Temperature == 0, 42, Temperature))

# Add weather data to inspections dataframe
inspections16 <- inspections16 %>%
 left_join(weather.Panel, by = "inspection_date") 

```

```{r import_weather_17, message = FALSE, warning = FALSE, cache = TRUE}
# Get 2017 weather data
weather.Panel <- 
  riem_measures(station = "ORD", date_start = "2017-01-01", date_end = "2017-12-31") %>%
  dplyr::select(valid, tmpf, p01i, sknt)%>%
  replace(is.na(.), 0) %>%
    mutate(inspection_date = as.Date(ymd_h(substr(valid,1,13)))) %>%
    mutate(week = week(inspection_date),
           dotw = wday(inspection_date, label=TRUE)) %>%
    group_by(inspection_date) %>%
    summarize(Temperature = max(tmpf),
              Precipitation = sum(p01i),
              Wind_Speed = max(sknt)) %>%
    mutate(Temperature = ifelse(Temperature == 0, 42, Temperature))

# Add weather data to inspections dataframe
inspections17 <- inspections17 %>%
 left_join(weather.Panel, by = "inspection_date") 

```

```{r import_weather_17, message = FALSE, warning = FALSE, cache = TRUE}
# Get 2018 weather data
weather.Panel <- 
  riem_measures(station = "ORD", date_start = "2018-01-01", date_end = "2018-12-31") %>%
  dplyr::select(valid, tmpf, p01i, sknt)%>%
  replace(is.na(.), 0) %>%
    mutate(inspection_date = as.Date(ymd_h(substr(valid,1,13)))) %>%
    mutate(week = week(inspection_date),
           dotw = wday(inspection_date, label=TRUE)) %>%
    group_by(inspection_date) %>%
    summarize(Temperature = max(tmpf),
              Precipitation = sum(p01i),
              Wind_Speed = max(sknt)) %>%
    mutate(Temperature = ifelse(Temperature == 0, 42, Temperature))

# Add weather data to inspections dataframe
inspections18 <- inspections18 %>%
 left_join(weather.Panel, by = "inspection_date") 

```

# Exploratory Data Analysis

First, we created some graphs of the model features and outcome variable. 

The risk category of each facility refers to how the establishment is categorized for its risk of adversely affecting the public's health, with 1 being the highest and 3 the lowest. The frequency of inspection is tied to this risk, with risk 1 establishments inspected most frequently and risk 3 least frequently. It can be seen that those restaurants in the "Risk 1 (High)" category are most likely to fail the inspection.


```{r risk_graph}
# Create a graph that looks at the categorical feature "risk"

inspections16 %>%
  st_drop_geometry() %>%
  dplyr::mutate(Results = ifelse(results_numeric==1, "Fail", "Pass")) %>%
  dplyr::select(Results, risk) %>%
  gather(Variable, value, -Results) %>%
  count(Variable, value, Results) %>%
  ggplot(aes(value, n, fill = Results)) +   
    geom_bar(position = "dodge", stat="identity") +
    scale_fill_manual(values = palette2) +
    labs(x="Inspection Result", y="Count",
         title = "Risk Categories and Inspection Results") +
    plotTheme + theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
As seen in Figure x and x, restaurants that fail inspection seem to have fewer past inspections and past failed inspections, more critical violations and number of violations overall, and more days since last inspection on average. Restaurants that fail inspection seem to have similar averages to the restaurants that pass inspection for temperature, days the restaurant has been operating, and median income and percent white of census tracts the restaurant is in. 

```{r continuous_graphs_1, message=FALSE, warning=FALSE}
# Check out differences in pass/fail for some of the continuous variables
inspections16 %>%
  st_drop_geometry() %>%
  dplyr::mutate(Results = ifelse(results_numeric==1, "Fail", "Pass")) %>%
  dplyr::select(Results, violations_count, critical_violations, past_inspect, past_failed_inspect, no_of_days, days_operating) %>%
  gather(Variable, value, -Results) %>%
    ggplot(aes(Results, value, fill=Results)) + 
      geom_bar(position = "dodge", stat = "summary", fun.y = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_fill_manual(values = palette2) +
      labs(x="Inspection Result", y="Value", 
           title = "Feature Associations with the Likelihood of Failed Inspection") +
      theme(legend.position = "none")
```

```{r continuous_graphs_2, message=FALSE, warning=FALSE}
# Check out differences in pass/fail for some more of the continuous variables
inspections16 %>%
  st_drop_geometry() %>%
  dplyr::mutate(Results = ifelse(results_numeric==1, "Fail", "Pass")) %>%
  dplyr::select(Results, Temperature, percentWhite, Median_Income) %>%
  gather(Variable, value, -Results) %>%
    ggplot(aes(Results, value, fill=Results)) + 
      geom_bar(position = "dodge", stat = "summary", fun.y = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_fill_manual(values = palette2) +
      labs(x="Inspection Result", y="Value", 
           title = "Feature Associations with the Likelihood of Failed Inspection") +
      theme(legend.position = "none")
```

Next we look at those restaurants that failed inspection across Chicago in 2016 (Figure ). It can be seen from Figure x and x that the majority of failed inspections occurred in the north east part of the city. The neighborhoods that had the most restaurants failing inspection were Lake View, Wicker Park/ West Town, and the Loop (Figure x). 

```{r failure_2016}

# Map of restaurants that failed inspection in 2016
inspections16_fail <- inspections16 %>% 
  filter(results_numeric == 1) %>%
  st_transform('ESRI:102271') 

ggplot() + 
  geom_sf(data=ChicagoBoundary) +
  geom_sf(data=chicagoNeighborhoods) +
  geom_sf(data=inspections16_fail, size=.3, color ="red") +
  labs(title = "Restaurants that Failed Inspection in 2016") +
  mapTheme()

```

```{r neighborhood_fails}
#Add variable for number of failed inspections by neighborhood
chicagoNeighborhoods$fail_count <- lengths(st_intersects(chicagoNeighborhoods, inspections16_fail))

ggplot(chicagoNeighborhoods) + 
  geom_sf(aes(fill = q5(fail_count))) +
  scale_fill_manual(values = palette5,labels = qBr(chicagoNeighborhoods, "fail_count"),name = "Inspection Failures\n(Quintile Breaks)") +
  labs(title = "Inspection Failures by Neighborhood") +
  mapTheme()
```

```{r 2016_inspections_by_neighborhood}
# bar plot of neighborhoods with the most failures (over 50)
inspections16_fail %>%
  st_drop_geometry() %>%
  dplyr::group_by(sec_neigh) %>%
  summarize(n = n()) %>%
  filter(n > 49) %>%
  filter(sec_neigh != "NA") %>%
  ggplot(aes(x=reorder(sec_neigh, n), y=n)) +
  geom_bar(stat = "identity", fill="#08519c") +
  coord_flip() +
  labs(x=" ", y="Count of Failed Inspections",
         title = "Count of Failed Inspections by Neighborhood") +
  plotTheme

```

Further, when we pull in census tract level data, we can see that the northeast part of the city where the most inspections occur is also home to Chicago's lower income census tracts (Figure x). 

```{r med_income_failure_2016}
# fixes projection issue
chicagoCensus <- chicagoCensus %>% 
   st_transform('ESRI:102271') 

# the census data has Cook County tracts that go beyond the city boundary - don't want to map those
selection <- 
  chicagoCensus[ChicagoBoundary,] 

ggplot(selection) + 
  geom_sf(aes(fill = q5(Median_Income))) +
  geom_sf(data=inspections16_fail, size=.2) +
  scale_fill_manual(values = rev(palette5b),labels = qBr(chicagoCensus, "Median_Income"),name = "Median_Income\n(Quintile Breaks)") +
  labs(title = "Inspection Failures and Median Income of Census Tracts ") +
  mapTheme()

```

Looking at the yearly weather trends (Figure x), we can see that wind speeds vary, but precipitation and temperature increase in spring and summer. As shown in Figure x, the likelihood of failing an inspection increases with higher temperatures. 

```{r plot_weather, catche = TRUE}
grid.arrange(
  ggplot(weather.Panel, aes(inspection_date,Precipitation)) + geom_line() + 
  labs(title="Precipitation", x="Day", y="Precipitation") + plotTheme,
  ggplot(weather.Panel, aes(inspection_date,Wind_Speed)) + geom_line() + 
    labs(title="Wind Speed", x="Day", y="Wind Speed") + plotTheme,
  ggplot(weather.Panel, aes(inspection_date,Temperature)) + geom_line() + 
    labs(title="Temperature", x="Day", y="Temperature") + plotTheme,
  top="Weather Data - Chicago ORD - 2016")
```

The number of inspections done each week seems to vary randomly across the year but hover around 200 inspections a week (Figure x). 

```{r inpsection_plot, cache = TRUE}

ggplot(inspections16 %>%
         st_drop_geometry() %>%
         dplyr::mutate(Week = week(inspections16$inspection_date)) %>%
         group_by(Week) %>%
         tally()) +
  geom_line(aes(x = Week, y = n), size=1, color="#08519c")+
  labs(title="Inspections per Week in Chicago, 2016",
       x="Week (1-52)", 
       y="Number of Inspections") +
  plotTheme
```

# Logistic Regression Model

The model developed here utilizes logistic regression, determining the likelihood of failing inspection and allowing us to classify a restaurant as likely to "fail" their next inspection or "pass" their next inspection. 

```{r warning=FALSE}
# Train/test split
inspections16 <- na.omit(inspections16)
set.seed(33343)
trainIndex <- createDataPartition(y = paste(inspections16$sec_neigh, inspections16$results_numeric), p = .65, list = FALSE, times=1)
inspectionTrain <- inspections16[ trainIndex,]
inspectionTest  <- inspections16[-trainIndex,]
```

```{r reg1_model}
# Logistic regression model with all of the variables- Kitchen sink model- Reg1
reg1 <- glm(results_numeric ~ .,
                  data=inspectionTrain %>% st_drop_geometry() %>% dplyr::select(inspection_type, critical_violations, violations_count, past_inspect, past_failed_inspect, no_of_days, sanitation_nn1, sanitation_nn2, sanitation_nn3, sanitation_nn4, sanitation_nn5, rodents_nn1, rodents_nn2, rodents_nn3, rodents_nn4, rodents_nn5, liquor_nn1, liquor_nn2, liquor_nn3, liquor_nn4, liquor_nn5, results_numeric, Temperature, Precipitation, Wind_Speed, days_operating, Median_Income, percentWhite, high_risk, sec_neigh),
                  family="binomial" (link="logit"))
summary(reg1)
```
In this model, we include the following selected features: high_risk, inspection_type, critical_violations, violations_count, days_operating, Temperature, liquor_nn5, sec_neigh, results_numeric.  

```{r reg2_model}
# Logistic regression model with selected variables - Reg2
reg2 <- glm(results_numeric ~ .,
                  data=inspectionTrain %>% st_drop_geometry() %>% dplyr::select(high_risk, inspection_type, critical_violations, violations_count, days_operating, Temperature, liquor_nn5, sec_neigh, results_numeric),
                  family="binomial" (link="logit"))
summary(reg2)

```

# Model Performance 

A confusion matrix is produced to show the goodness of fit of the model. A positive parameter is specified to let the function know that a value of 1 designates failing inspection. Our sensitivity (trust positive rate) is 0.72, which greatly improved after our feature engineering. Our specificity (true negative rate) is high at 0.87. Accuracy is also high at 0.8369. An optimal threshold of 0.29 was used to produce this confusion matrix (see below for analysis).

```{r model_metrics}
# Reg 2 model metrics
testProbs <- data.frame(Outcome = as.factor(inspectionTest$results_numeric),
                        Probs = predict(reg2, inspectionTest, type= "response"))

testProbs <- testProbs %>% mutate(predOutcome  = as.factor(ifelse(testProbs$Probs > 0.29 , 1, 0)))

caret::confusionMatrix(testProbs$predOutcome, testProbs$Outcome, 
                       positive = "1")

cm16 <- confusionMatrix(testProbs$predOutcome, testProbs$Outcome, 
                     positive = "1")

Accuracy16 <- cm16$overall['Accuracy']
```

```{r}
cost_benefit_table <-
   testProbs %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
       gather(Variable, Count) %>%
    bind_cols(data.frame(Description = c(
              "We predicted pass and the restaurant passed inspection",
              "We predicted failure and the restaurant failed inspection",
              "We predicted pass and the restaurant failed inspection",
              "We predicted failure and the restaurant passed inspection")))
kable(cost_benefit_table) %>% 
  kable_styling(font_size = 12, full_width = F,
                bootstrap_options = c("striped", "hover", "condensed")) 
```

## ROC Curve

The AUC (Area Under the Curve) for our model is 0.89, which indicates a good, useful fit. The graph supports this finding, with the curve being above the coin flip line but below the perfect fit line. 

```{r message=FALSE, warning=FALSE}
# ROC Curve
ggplot(testProbs, aes(d = as.numeric(testProbs$Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#08519c") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve")
```


```{r message=FALSE, warning=FALSE}
pROC::auc(testProbs$Outcome, testProbs$Probs)
```

## Cross Validation

Next we cross validate our model to further assess goodness of fit and see if our model results hold across 100 held out test sets (instead of just 1). We can see the model has a mean AUC that is around 0.88, which indicates a good fit. Our model generalizes less well with respect to Sensitivity, which is the rate it correctly predicts true positives (restaurants that fail inspection). This Sensitivity value has increased with additional feature engineering, which shows the importance of that work (and indicates that further feature engineering could make the model even better). Our model generalized well with respect to Specificity, which is the rate it correctly predicts true negatives (restaurants that pass inspection).  

```{r cv, message=FALSE, warning=FALSE}

ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)
cvFit.reg2 <- train(results_numeric ~ ., data = inspections16 %>% st_drop_geometry() %>%
                                   dplyr::select(high_risk, inspection_type, critical_violations, violations_count, days_operating, Temperature, liquor_nn5, sec_neigh, results_numeric) %>%
                      dplyr::mutate(results_numeric = ifelse(results_numeric==1,"fail","pass")),
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)
cvFit.reg2
```

```{r}
# Model metrics - Reg2
dplyr::select(cvFit.reg2$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit.reg2$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#6baed6") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#08519c", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics Reg2",
         subtitle = "Across-fold mean reprented as dotted lines") +
    plotTheme
```

## Optimal Threshold

In this section, a function is created to iteratively loop through each threshold and calculate confusion metrics for each. The results are then examined by threshold to optimize. We find that the threshold of xxxx limits the false negatives (those we predict to pass but fail) and false positives (those we predict to fail but pass). We want to limit false negatives because incorrectly labeling a failed inspection as a pass means that customers using the app may be vulnerable to food borne illnesses at a restaurant they choose to go to. We want to limit false positives because it can be hurtful for businesses for their restaurants to be flagged when really they would pass inspection. We also want a threshold that keeps accuracy high. It looks like the optimal threshold for this model is 0.29, which minimizes True Postives and True Negative while keeping Accuracy high. 

```{r}
iterateThresholds <- function(data, observedClass, predictedProbs, group) {
#This function takes as its inputs, a data frame with an observed binomial class (1 or 0); a vector of predicted probabilities; and optionally a group indicator like race. It returns accuracy plus counts and rates of confusion matrix outcomes. It's a bit verbose because of the if (missing(group)). I don't know another way to make an optional parameter.
  observedClass <- enquo(observedClass)
  predictedProbs <- enquo(predictedProbs)
  group <- enquo(group)
  x = .01
  all_prediction <- data.frame()
  
  if (missing(group)) {
  
    while (x <= 1) {
    this_prediction <- data.frame()
    
    this_prediction <-
      data %>%
      mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
      count(predclass, !!observedClass) %>%
      summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
                Count_TP = sum(n[predclass==1 & !!observedClass==1]),
                Count_FN = sum(n[predclass==0 & !!observedClass==1]),
                Count_FP = sum(n[predclass==1 & !!observedClass==0]),
                Rate_TP = Count_TP / (Count_TP + Count_FN),
                Rate_FP = Count_FP / (Count_FP + Count_TN),
                Rate_FN = Count_FN / (Count_FN + Count_TP),
                Rate_TN = Count_TN / (Count_TN + Count_FP),
                Accuracy = (Count_TP + Count_TN) / 
                           (Count_TP + Count_TN + Count_FN + Count_FP)) %>%
      mutate(Threshold = round(x,2))
    
    all_prediction <- rbind(all_prediction,this_prediction)
    x <- x + .01
  }
  return(all_prediction)
  }
  else if (!missing(group)) { 
   while (x <= 1) {
    this_prediction <- data.frame()
    
    this_prediction <-
      data %>%
      mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
      group_by(!!group) %>%
      count(predclass, !!observedClass) %>%
      summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
                Count_TP = sum(n[predclass==1 & !!observedClass==1]),
                Count_FN = sum(n[predclass==0 & !!observedClass==1]),
                Count_FP = sum(n[predclass==1 & !!observedClass==0]),
                Rate_TP = Count_TP / (Count_TP + Count_FN),
                Rate_FP = Count_FP / (Count_FP + Count_TN),
                Rate_FN = Count_FN / (Count_FN + Count_TP),
                Rate_TN = Count_TN / (Count_TN + Count_FP),
                Accuracy = (Count_TP + Count_TN) / 
                           (Count_TP + Count_TN + Count_FN + Count_FP)) %>%
      mutate(Threshold = round(x,2))
    
    all_prediction <- rbind(all_prediction,this_prediction)
    x <- x + .01
  }
  return(all_prediction)
  }
}
```

```{r}
whichThreshold <- 
  iterateThresholds(
     data=testProbs, observedClass = Outcome, predictedProbs = Probs)
whichThreshold <- as.data.frame(whichThreshold)
```

## Model Performance on Next Year's Data 
### 2017

```{r model_metrics_17}
# In the 2017 inspection data, the KENWOOD,OAKLAND neighborhood has two entries that are instead "OAKLAND,KENWOOD", so I fix those
inspections17$sec_neigh[inspections17$sec_neigh == "OAKLAND,KENWOOD"] <- "KENWOOD,OAKLAND"

# Reg 2 model metrics
testProbs17 <- data.frame(Outcome = as.factor(inspections17$results_numeric),
                        Probs = predict(reg2, inspections17, type= "response"))

testProbs17 <- testProbs17 %>% mutate(predOutcome  = as.factor(ifelse(testProbs17$Probs > 0.41 , 1, 0)))

caret::confusionMatrix(testProbs17$predOutcome, testProbs17$Outcome, 
                       positive = "1")

cm17 <- confusionMatrix(testProbs17$predOutcome, testProbs17$Outcome, 
                     positive = "1")

Accuracy17 <- cm17$overall['Accuracy']
```

Looking at the predictions we got incorrect in 2017, we can see they are fairly evenly distributed across space, with the bulk appearing in downtown and the north east part of the city (where we see the most inspections and failed inspections). 

```{r}
# Map of predictions
inspections17 <- inspections17 %>% 
  dplyr::mutate(Prob = predict(reg2, inspections17, type= "response")) %>%
  dplyr::mutate(predictedOutcome  = as.factor(ifelse(inspections17$Prob > 0.29 , 1, 0))) %>%
  dplyr::mutate(incorrect_prediction = ifelse((results_numeric==1 & predictedOutcome==0), 1, ifelse((results_numeric==0 & predictedOutcome==1), 1, 0)))

#mutate giving me issues so 
inspections17$Prob <- predict(reg2, inspections17, type= "response")
inspections17$predictedOutcome <- as.factor(ifelse(inspections17$Prob > 0.29 , 1, 0))
inspections17$incorrect_prediction <- ifelse((inspections17$results_numeric==1 & inspections17$predictedOutcome==0), 1, ifelse((inspections17$results_numeric==0 & inspections17$predictedOutcome==1), 1, 0))

ggplot() + 
  geom_sf(data=ChicagoBoundary) +
  geom_sf(data=chicagoNeighborhoods) +
  geom_sf(data = inspections17, aes(colour = factor(incorrect_prediction)), 
          show.legend = "point", size = .5) +
  scale_colour_manual(values = c("#7bccc4", "#08519c"),
                   name="Incorrect Prediction") +
  labs(title="Incorrect Predictions Across Chicago") +
  mapTheme()
 
```

### 2018

```{r model_metrics_18}
# In the 2018 inspection data, the KENWOOD,OAKLAND neighborhood has two entries that are instead "OAKLAND,KENWOOD", so I fix those
inspections18$sec_neigh[inspections18$sec_neigh == "OAKLAND,KENWOOD"] <- "KENWOOD,OAKLAND"

# Reg 2 model metrics
testProbs18 <- data.frame(Outcome = as.factor(inspections18$results_numeric),
                        Probs = predict(reg2, inspections18, type= "response"))

testProbs18 <- testProbs18 %>% mutate(predOutcome  = as.factor(ifelse(testProbs18$Probs > 0.41 , 1, 0)))

caret::confusionMatrix(testProbs18$predOutcome, testProbs18$Outcome, 
                       positive = "1")

cm18 <- confusionMatrix(testProbs18$predOutcome, testProbs18$Outcome, 
                     positive = "1")

Accuracy18 <- cm18$overall['Accuracy']
```
### Comparison

We can see that model accuracy is decreasing as we test model performance on subsequent years' data. The model was built with 2016 data and performs almost as well on 2017 data. On 2018 data, model performance decreases. This shows the importance of having our model updated yearly. Model engineers will use this code to refit the model and confirm the appropriateness of features every year. This will help avoid the decrease in performance as years pass. 

```{r accuracy}

Accuracy <- c(Accuracy16, Accuracy17, Accuracy18)
Year <- c(2016, 2017, 2018)
accuracy<- data.frame(Year, Accuracy)

ggplot(data=accuracy, aes(x=as.factor(Year), y=Accuracy)) +
  geom_bar(stat="identity", width = .7, fill="#7bccc4") +
  geom_text(aes(label = round(Accuracy,3)), vjust = -0.3)+
  labs(x="Year", y="Accuracy", title="Model Accuracy Across Years",
         subtitle = "2016 model performance tested on 2017 and 2018 data") +
  theme(
  plot.title =element_text(size=12),
  plot.subtitle = element_text(size=8),
  plot.caption = element_text(size = 6),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title.y = element_text(size = 10),
  # Set the entire chart region to blank
  panel.background=element_blank(),
  plot.background=element_blank(),
  #panel.border=element_rect(colour="#F0F0F0"),
  # Format the grid
  panel.grid.major=element_line(colour="#D0D0D0",size=.2),
  axis.ticks=element_blank())

```


# Conclusion

This analysis shows how a machine learning model can be used to predict whether restaurants will pass or fail their next health inspection based on restaurant characteristics, spatial features, and weather. This prediction can then be deployed in an App to help inform the public about which restaurants may pose risks to their health. The analysis proves this kind of model performs fairly well and shows the utility of a machine learning model in this use case. 

It is important to note the limitations of this analysis. We have built a model that classifies a restaurant into two classes "pass" or "fail" - there is no middle ground (or risk score) in this analysis. This has implications, especially for those restaurants that the model predicts "fail" for. These restaurants are flagged in the app, thus likely deterring the public from eating at their restaurant. A false positive (where we predict fail but the restaurant actually passes) is very harmful to a restaurant's business - and we want to limit that. Our model is not perfect, and our results showed our model still had some False Positives, so backlash from some restaurants could be expected post deployment. On the other hand, the health of the public is also important, and the wrong prediction could lead to sick Chicagoans - thus our priority is to limit false negatives. Our model also still had some False negatives, so it is possible to classify a restaurant as safe when it is not. Knowing these risks to the public and businesses, future analyses could incorporate a risk score instead of a fail/ pass classification. Further, our model has room to improve when it comes to sensitivity (the rate at which the model predicts a restaurant will fail and it does). To make this analysis better, we recommend more feature engineering that better explains the variance between a failing restaurant and a passing restaurant. Further, we imagine failures to vary by the inspector doing the inspection. We believe that having the data on the inspector assigned could improve our model. 

Despite these limitations, the model developed and analyzed here is fairly accurate and generalizes well. The model behind the the EatSafe app will also be re-analyzed and developed each year using updated data, which should improve the accuracy of predictions in future years and better protect the public and restaurants. We believe this model can help the public make an informed decision about where they eat, which is especially important to maintain hygiene standards during the pandemic! 















OLD CODE: 

```{r}
reg.vars <- c("rodents_nn5", "sanitation_nn5", "violations_count", "risk")

inspections16 <- inspections16 %>%
  mutate(cvID = sample(round(nrow(inspections16) / 120), size=nrow(inspections16), replace = TRUE))

crossValidate <- function(dataset, id, dependentVariable, indVariables) {

allPredictions <- data.frame()
cvID_list <- unique(dataset[[id]])

for (i in cvID_list) {

  thisFold <- i
  cat("This hold out fold is", thisFold, "\n")

  fold.train <- filter(dataset, dataset[[id]] != thisFold) %>% as.data.frame() %>% 
                dplyr::select(id, geometry, indVariables, dependentVariable)
  fold.test  <- filter(dataset, dataset[[id]] == thisFold) %>% as.data.frame() %>% 
                dplyr::select(id, geometry, indVariables, dependentVariable)
  
  regression <-
    glm(results_numeric ~ ., family = "binomial" (link="logit"), 
      data = fold.train %>% 
      dplyr::select(-geometry, -id))
  
  thisPrediction <- 
    mutate(fold.test, Prediction = predict(regression, fold.test, type = "response"))
    
  allPredictions <-
    rbind(allPredictions, thisPrediction)
    
  }
  return(st_sf(allPredictions))
}
```

```{r message=FALSE, warning=FALSE}
reg.cv <- crossValidate(
  dataset = inspections16,
  id = "cvID",
  dependentVariable = "results_numeric",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, inspections16, Prediction, geometry)

```


# inspectionCount
# Create feature for # of previous inspections
#inspections <- inspections %>%
 # arrange(inspection_date) %>%
  # group_by(dba_name) %>%
   #mutate(inspectionCount = row_number() - 1L) %>%
   #ungroup()
   
```{r get_census, message=FALSE, warning=FALSE, cache=TRUE, results = 'hide'}
## don't think we need this but will leave here for now
chicagoCensus <- 
  get_acs(geography = "tract", 
          variables = c("B01003_001", "B19013_001", 
                        "B02001_002", "B08013_001",
                        "B08012_001", "B08301_001", 
                        "B08301_010", "B01002_001"), 
          year = 2017, 
          state = "IL", 
          geometry = TRUE, 
          county=c("Cook"),
          output = "wide") %>%
  rename(Total_Pop =  B01003_001E,
         Med_Inc = B19013_001E,
         Med_Age = B01002_001E,
         White_Pop = B02001_002E,
         Travel_Time = B08013_001E,
         Num_Commuters = B08012_001E,
         Means_of_Transport = B08301_001E,
         Total_Public_Trans = B08301_010E) %>%
  select(Total_Pop, Med_Inc, White_Pop, Travel_Time,
         Means_of_Transport, Total_Public_Trans,
         Med_Age,
         GEOID, geometry) %>%
  mutate(Percent_White = White_Pop / Total_Pop,
         Mean_Commute_Time = Travel_Time / Total_Public_Trans,
         Percent_Taking_Public_Trans = Total_Public_Trans / Means_of_Transport)

```



```{r extract_geometries, cache = TRUE}
chicagoTracts <- 
  chicagoCensus %>%
  as.data.frame() %>%
  distinct(GEOID, .keep_all = TRUE) %>%
  select(GEOID, geometry) %>% 
  st_sf 

inspections16 <- inspections16 %>% st_transform(4326) 

```

```{r add_census_tracts, cache = TRUE, message = FALSE, warning = FALSE}
# this creates a new data frame with inspections and census data - not an sf object
dat_census <- st_join(inspections16 %>% 
          filter(is.na(location.latitude) == FALSE &
                   is.na(location.longitude) == FALSE) %>%
          st_as_sf(., coords = c("location.longitude", "location.latitude"), crs = 4326),
        chicagoTracts %>%
          st_transform(crs=4326),
        join=st_intersects,
              left = TRUE) %>%
  rename(Origin.Tract = GEOID) %>%
  mutate(location.longitude = unlist(map(geometry, 1)),
         location.latitude = unlist(map(geometry, 2)))%>%
  as.data.frame() %>%
  select(-geometry)
 
```

```{r}
inspections16 %>%
  st_drop_geometry() %>%
  ggplot(aes(x=days_operating, y=past_failed_inspect)) +
   geom_point(size=.4) +
    geom_smooth(method=lm)
  
  
```